---

# Needed to ensure some services start properly
- name: Set hostname
  become: yes
  lineinfile:
    dest: /etc/hosts
    line: "127.0.0.1 {{ ansible_hostname }}"
  notify:
    - restart kafka

- name: Copy AWS autodiscover script
  become: yes
  become_user: "{{ kafka_user }}"
  copy:
    src: aws_cluster_autodiscover
    dest: "/home/{{ kafka_user }}/bin/aws_cluster_autodiscover"
    owner: "{{ kafka_user }}"
    group: "{{ kafka_group }}"
    mode: 0750
  when: kafka_aws_cluster_autodiscover_enabled

- name: Run AWS autodiscover script and grab cluster settings
  become: yes
  become_user: "{{ kafka_user }}"
  command: "./aws_cluster_autodiscover {{ kafka_aws_cluster_autodiscover_hosts | join(',') }} {{ kafka_aws_cluster_autodiscover_r53_zone_id }} \"{{ kafka_aws_cluster_autodiscover_lookup_filter }}\" {{ kafka_aws_cluster_autodiscover_id_tag_name}}"
  args:
    chdir: "/home/{{ kafka_user }}/bin"
  register: aws_cluster_autodiscover
  until: aws_cluster_autodiscover | success
  retries: 4
  delay: 10
  when: kafka_aws_cluster_autodiscover_enabled

# Combine is used with set fact as successive calls to the module
# seem to remove previous values added to hashes
- name: Set cluster facts based on AWS autodiscover script output
  set_fact:
    kafka: "{{ kafka | combine( {
        'aws_cluster_autodiscover': {
          'data': aws_cluster_autodiscover.stdout | from_json
        }
      }, recursive=True) }}"
  when: kafka_aws_cluster_autodiscover_enabled

- name: Export DNS hostname
  become: yes
  become_user: "{{ kafka_user }}"
  lineinfile:
    create: yes
    dest: "/home/{{ kafka_user }}/etc/hostname"
    line: "{{ kafka_aws_cluster_autodiscover_data_hostname }}"
  when: kafka_aws_cluster_autodiscover_enabled

- name: Export hosted zone ID from aws_cluster_autodiscover settings
  become: yes
  become_user: "{{ kafka_user }}"
  lineinfile:
    create: yes
    dest: "/home/{{ kafka_user }}/etc/hostedZone"
    line: "{{ kafka_aws_cluster_autodiscover_r53_zone_id }}"
  when: kafka_aws_cluster_autodiscover_enabled

- name: Export broker ID to local filesystem
  become: yes
  become_user: "{{ kafka_user }}"
  lineinfile:
    create: yes
    dest: "/home/{{ kafka_user }}/etc/brokerId"
    line: "{{ kafka_aws_cluster_autodiscover_data_id }}"
  when: kafka_aws_cluster_autodiscover_enabled

- name: Assigned ID EC2 fact hunt
  action: ec2_facts
  register: ec2_vars
  until: ec2_vars | success
  retries: 3
  delay: 5
  when: kafka_aws_cluster_assigned_id_enabled

- name: Assigned ID grab tags from EC2 instance
  ec2_tag:
    region: "{{ ansible_ec2_placement_region }}"
    resource: "{{ ansible_ec2_instance_id }}"
    state: list
  register: assigned_id_instance_tags
  when: ansible_ec2_instance_id is defined
    and kafka_aws_cluster_assigned_id_enabled
  retries: 3
  delay: 5
  until: assigned_id_instance_tags | success

- name: Assigned ID set Broker ID
  set_fact:
    kafka: "{{ kafka | combine( {
        'id': assigned_id_instance_tags.tags[kafka_aws_cluster_assigned_id_id_tag_name]
      }, recursive=True) }}"
  when: ansible_ec2_instance_id is defined
    and kafka_aws_cluster_assigned_id_enabled

- name: Grab local facts for looking up interfaces
  action: setup
  register: local_facts
  when: kafka_interface_bind
    or kafka_interface_advertise

- name: Set listen_address if interface bind set
  set_fact:
    kafka: "{{ kafka | combine( {
        'listen_address': local_facts.ansible_facts['ansible_' + kafka_interface_bind]['ipv4']['address']
      }, recursive=True) }}"
  when: kafka_interface_bind

- name: Set advertised_host_name if interface advertise set
  set_fact:
    kafka: "{{ kafka | combine( {
        'advertised_host_name': local_facts.ansible_facts['ansible_' + kafka_interface_advertise]['ipv4']['address']
      }, recursive=True) }}"
  when: kafka_interface_advertise

- name: Setup environment config
  become: yes
  become_user: "{{ kafka_user }}"
  template:
    dest: "/home/{{ kafka_user }}/etc/environment"
    mode: 0644
    src: environment.j2
  notify:
    - restart kafka

- name: Create log4j.properties
  become: yes
  become_user: "{{ kafka_user }}"
  template:
    dest: "/home/{{ kafka_user }}/etc/log4j.properties"
    mode: 0644
    src: log4j.properties.j2
  notify:
    - restart kafka

- name: Create server.properties
  become: yes
  become_user: "{{ kafka_user }}"
  template:
    dest: "/home/{{ kafka_user }}/etc/server.properties"
    mode: 0640
    src: server.properties.j2
  notify:
    - restart kafka

- name: Enable JMX
  become: yes
  become_user: "{{ kafka_user }}"
  lineinfile:
    path: "/home/{{ kafka_user }}/kafka/bin/kafka-run-class.sh"
    line: "KAFKA_JMX_OPTS=\"-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname={{ openstack['public_v4'] }} -Dcom.sun.management.jmxremote.port={{ kafka_jmx_port }} -Dcom.sun.management.jmxremote.rmi.port={{ kafka_jmx_port }}\""
    insertafter: "#!/bin/bash"
  when: kafka_enable_jmx

- name: Ensure Kafka is running
  service:
    name: kafka
    state: started

- name: Flush handlers to ensure Kafka is up to date
  meta: flush_handlers

- name: Wait for Kafka port
  wait_for:
    port: "{{ kafka_port }}"
    state: started
    timeout: "{{ kafka_wait_for_kafka_port }}"

- name: Copy Kafka maintenance scripts
  become: yes
  become_user: "{{ kafka_user }}"
  copy:
    src: "{{ item }}"
    mode: 0750
    dest: "/home/{{ kafka_user }}/bin/{{ item }}"
  with_items:
    - kafka_maintenance_at_stop
    - kafka_maintenance_at_start
    - remove_dns_record
  when: kafka_aws_cluster_autodiscover_enabled

- name: Run Kafka maintenance script at start
  become: yes
  become_user: "{{ kafka_user }}"
  shell: "/home/{{ kafka_user }}/bin/kafka_maintenance_at_start"
  when: kafka_aws_cluster_autodiscover_enabled

- name: Copy Kafka stop script
  become: yes
  copy:
    dest: "/etc/init.d"
    mode: 0755
    src: "stop_kafka"
  when: kafka_aws_cluster_autodiscover_enabled

- name: Add Kafka stop script to system runlevels
  become: yes
  file:
    src: "/etc/init.d/stop_kafka"
    dest: "/etc/{{ item }}/K10kafka-controlled-shutdown"
    state: link
    force: yes
  with_items:
    - "rc0.d"
    - "rc1.d"
    - "rc6.d"
  when: kafka_aws_cluster_autodiscover_enabled
